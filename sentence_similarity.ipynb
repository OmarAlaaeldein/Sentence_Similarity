{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec,FastText\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORD2VEC \n",
    "W2V_SIZE = 512 # try to tweak , was 300\n",
    "W2V_WINDOW = 8 # context window\n",
    "W2V_EPOCH = 32 # to optimize was 32 by default\n",
    "W2V_MIN_COUNT = 8 # to optimize was 32 or 16 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText.load(\"fasttext.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['how'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your preprocessed corpus\n",
    "#df = pd.read_csv(\"corpus.csv\")\n",
    "\n",
    "# Assuming df['text'] contains list of tokenized preprocessed sentences\n",
    "#sentences = df['text'].tolist()\n",
    "\n",
    "# Train a FastText model with Gensim (uncomment the following lines to use FastText)\n",
    "#model = FastText(vector_size=W2V_SIZE, window=W2V_WINDOW, min_count=W2V_MIN_COUNT, workers=16)\n",
    "\n",
    "# Or Train a Word2Vec model with Gensim (comment the following lines if you use FastText)\n",
    "# model = Word2Vec(vector_size=512, window=5, min_count=1, workers=16)\n",
    "\n",
    "# Building the vocabulary\n",
    "#model.build_vocab(sentences)\n",
    "\n",
    "# Training the model\n",
    "#model.train(sentences, total_examples=model.corpus_count, epochs=W2V_EPOCH)\n",
    "\n",
    "def sentence_vector(sentence, model):\n",
    "    words = sentence.split(\" \")\n",
    "    \n",
    "    # Add a neutral word if the number of words is even\n",
    "    if len(words) % 2 == 0:\n",
    "        words.append(\".\")  # Use the \".\" character as a neutral word, assume it is in the vocabulary\n",
    "\n",
    "    # Prepare the sequence of vectors\n",
    "    size=len(model.wv['how'])\n",
    "    vectors = [model.wv[words[idx]].reshape(size,1) for idx in range(len(words))]\n",
    "   \n",
    "    # Convert the vectors to tensors\n",
    "    #tensors = [tf.constant(vector, dtype=tf.float32) for vector in vectors]\n",
    "    #tensors=np.array(tensors).reshape(len(words),size,1)\n",
    "    \n",
    "    # Use tf.linalg.matvec to perform the dot product operations\n",
    "    #sentence_vector = tensors[0]\n",
    "    sentence_vector = vectors[0]\n",
    "    print(len(vectors))\n",
    "    for i in range(1, len(vectors)):\n",
    "        #print(i)\n",
    "        if i%2==1:\n",
    "            #print(sentence_vector.shape)\n",
    "            #print(tensors[i].T.shape)\n",
    "            #sentence_vector = tf.linalg.matvec(sentence_vector.reshape(size,1), tensors[i].reshape(1,size))\n",
    "            #print(sentence_vector.shape)\n",
    "            #print(vectors[i].T.shape)\n",
    "            sentence_vector= sentence_vector@vectors[i].T\n",
    "        else:\n",
    "            #print(sentence_vector.shape)\n",
    "            #print(tensors[i].shape)\n",
    "            #sentence_vector = tf.linalg.matvec(sentence_vector, tensors[i])\n",
    "            #print(sentence_vector.shape)\n",
    "            #print(vectors[i].shape)\n",
    "            sentence_vector= sentence_vector@vectors[i]\n",
    "    #print(sentence_vector.shape)\n",
    "    return sentence_vector\n",
    "\n",
    "def cosine_similarity_func(vec1, vec2):\n",
    "    vec1 = vec1.reshape(1, -1)\n",
    "    vec2 = vec2.reshape(1, -1)\n",
    "    return cosine_similarity(vec1, vec2)[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "5\n",
      "Similarity:  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's compute the sentence vectors for two sentences\n",
    "sentence1 = \"The woman did play the guitar\"\n",
    "sentence2 = \"The man played the piano\"\n",
    "\n",
    "vector1 = sentence_vector(sentence1, model)\n",
    "vector2 = sentence_vector(sentence2, model)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity = cosine_similarity_func(vector1, vector2)\n",
    "#print(similarity.shape)\n",
    "print(\"Similarity: \", similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
